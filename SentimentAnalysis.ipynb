{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303c1be7-af29-4197-bb45-27d0df6132e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19180439-6b97-4032-981a-dcc8e5daa3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5b363b-aae8-4481-847f-396ae8a44621",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072e9f95-5a30-4f4d-88fc-19223b5f0970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55430ba3-8414-42e7-8d5b-bba3df1c25c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAV = 'RAVDESS Emotional speech audio/audio_speech_actors_01-24/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d788d1-82f3-4253-8381-c93993bfbb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = os.listdir(RAV)\n",
    "dir_list = os.listdir(RAV)\n",
    "dir_list = [item for item in dir_list if not item.startswith('.')] \n",
    "dir_list.sort()\n",
    "dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b05198-37a8-44cb-99b4-258f6f1264ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dir_list = os.listdir(RAV)\n",
    "dir_list.sort()\n",
    "\n",
    "emotion = []\n",
    "gender = []\n",
    "path = []\n",
    "for i in dir_list:\n",
    "    folder_path = os.path.join(RAV, i)\n",
    "    if os.path.isdir(folder_path):\n",
    "        fname = os.listdir(folder_path)\n",
    "        for f in fname:\n",
    "            file_path = os.path.join(folder_path, f) \n",
    "            part = f.split('.')[0].split('-')\n",
    "            emotion.append(int(part[2]))\n",
    "            temp = int(part[6])\n",
    "            if temp%2 == 0:\n",
    "                temp = \"female\"\n",
    "            else:\n",
    "                temp = \"male\"\n",
    "            gender.append(temp)\n",
    "            path.append(RAV + i + '/' + f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e011c19-57e3-4d43-b266-1d22ac070236",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAV_df = pd.DataFrame(emotion)\n",
    "RAV_df = RAV_df.replace({1:'neutral', 2:'neutral', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'})\n",
    "RAV_df = pd.concat([pd.DataFrame(gender), RAV_df], axis=1)\n",
    "RAV_df.columns = ['gender', 'emotion']\n",
    "RAV_df['labels'] = RAV_df.gender + '_' + RAV_df.emotion\n",
    "RAV_df['source'] = 'RAVDESS'\n",
    "RAV_df = pd.concat([RAV_df, pd.DataFrame(path, columns=['path'])], axis=1)\n",
    "RAV_df = RAV_df.drop(['gender', 'emotion'], axis=1)\n",
    "\n",
    "print(RAV_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dbd1ac-6544-44a5-a8b8-09e37f7dd013",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAV_df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fb9d45-dd1e-4c51-9ce8-c6724cfdfb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = RAV + 'Actor_14/03-01-06-02-02-02-14.wav'\n",
    "data, sample_rate = librosa.load(fname)\n",
    "plt.figure(figsize = (15, 5))\n",
    "librosa.display.waveshow(data, sr = sample_rate)\n",
    "plt.title('FEAR', size = 25)\n",
    "\n",
    "\n",
    "ipd.Audio(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde46b0e-410a-4056-9509-7bf2130b9037",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = RAV + 'Actor_14/03-01-03-02-02-02-14.wav'  \n",
    "data, sampling_rate = librosa.load(fname)\n",
    "plt.figure(figsize=(15, 5))\n",
    "librosa.display.waveshow(data, sr=sampling_rate)\n",
    "plt.title('Happy', size = 25)\n",
    "\n",
    "ipd.Audio(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a652216-c1bd-4b17-8648-7c250f67bbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([RAV_df], axis = 0)\n",
    "plt.figure(figsize = (20, 6))\n",
    "df.labels.value_counts().plot(kind = 'bar')\n",
    "print(df.labels.value_counts())\n",
    "df.head()\n",
    "df.to_csv(\"Data_path.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a399fe-6f4b-4f75-ba48-88b86a318fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "emotion_labels = {\n",
    "    'neutral': '01',\n",
    "    'happy': '03',\n",
    "    'sad': '04',\n",
    "    'angry': '05',\n",
    "    'fearful': '06',\n",
    "    'disgust': '07',\n",
    "    'surprised': '08'\n",
    "}\n",
    "\n",
    "for emotion, label in emotion_labels.items():\n",
    "    fname = f\"{RAV}Actor_14/03-01-{label}-01-02-01-14.wav\"\n",
    "    \n",
    "    data, sampling_rate = librosa.load(fname)\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    librosa.display.waveshow(data, sr=sampling_rate)\n",
    "    plt.title(emotion.capitalize(), size=25)\n",
    "    \n",
    "    ipd.display(ipd.Audio(fname))\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e563d97d-d414-49fd-83aa-4e1ac22f6e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised\n",
    "#actor_number = 1-24\n",
    "emotion = 'angry'\n",
    "emotion_label = '05'\n",
    "actor_number = '16'\n",
    "fname = f\"{RAV}Actor_{actor_number}/03-01-{emotion_label}-01-02-01-{actor_number}.wav\"\n",
    "\n",
    "# Load and visualize the audio\n",
    "data, sampling_rate = librosa.load(fname)\n",
    "plt.figure(figsize=(15, 5))\n",
    "librosa.display.waveshow(data, sr=sampling_rate)\n",
    "plt.title(emotion.capitalize(), size=25)\n",
    "\n",
    "# Play the audio\n",
    "ipd.display(ipd.Audio(fname))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5e0b14-d78e-441b-9229-f59b72e91105",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_mapping = {\n",
    "    '01': 'neutral',\n",
    "    '03': 'happy',\n",
    "    '04': 'sad',\n",
    "    '05': 'angry',\n",
    "    '06': 'fearful',\n",
    "    '07': 'disgust',\n",
    "    '08': 'surprised'\n",
    "}\n",
    "\n",
    "emotion_label = '03'\n",
    "actor_number = '07'\n",
    "\n",
    "\n",
    "emotion = emotion_mapping.get(emotion_label, 'unknown')\n",
    "\n",
    "\n",
    "fname = f\"{RAV}Actor_{actor_number}/03-01-{emotion_label}-01-02-01-{actor_number}.wav\"\n",
    "\n",
    "\n",
    "data, sampling_rate = librosa.load(fname)\n",
    "plt.figure(figsize=(15, 5))\n",
    "librosa.display.waveshow(data, sr=sampling_rate)\n",
    "plt.title(emotion.capitalize(), size=25)\n",
    "\n",
    "ipd.display(ipd.Audio(fname))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274c4f7b-b35c-4c4c-8182-7a30658d77e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ipywidgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae366ab-58ad-4138-8fe4-c225493a92f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_mapping = {\n",
    "    '01': 'neutral',\n",
    "    '03': 'happy',\n",
    "    '04': 'sad',\n",
    "    '05': 'angry',\n",
    "    '06': 'fearful',\n",
    "    '07': 'disgust',\n",
    "    '08': 'surprised'\n",
    "}\n",
    "\n",
    "def format_actor_number(actor_number):\n",
    "    return f\"{actor_number:02d}\"\n",
    "\n",
    "\n",
    "emotion_label_input = widgets.Dropdown(\n",
    "    options=[('Neutral', '01'), ('Happy', '03'), ('Sad', '04'), ('Angry', '05'), ('Fearful', '06'), ('Disgust', '07'), ('Surprised', '08')],\n",
    "    description='Emotion Label:'\n",
    ")\n",
    "actor_number_input = widgets.IntText(description='Actor Number:')\n",
    "analyze_button = widgets.Button(description='Analyze Audio')\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "def analyze_audio(button):\n",
    "    emotion_label = emotion_label_input.value\n",
    "    actor_number = format_actor_number(actor_number_input.value)\n",
    "    \n",
    "    \n",
    "    emotion = emotion_mapping.get(emotion_label, 'unknown')\n",
    "    \n",
    "    \n",
    "    fname = f\"{RAV}Actor_{actor_number}/03-01-{emotion_label}-01-02-01-{actor_number}.wav\"\n",
    "    \n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        # Load and visualize the audio\n",
    "        data, sampling_rate = librosa.load(fname)\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        librosa.display.waveshow(data, sr=sampling_rate)\n",
    "        plt.title(emotion.capitalize(), size=25)\n",
    "\n",
    "        \n",
    "        ipd.display(ipd.Audio(fname))\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "analyze_button.on_click(analyze_audio)\n",
    "\n",
    "\n",
    "display(emotion_label_input, actor_number_input, analyze_button, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310ad7e3-d1a2-42f2-aa4f-24530df18216",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91455c55-3653-427c-b4b0-3e9511a3e40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_features(audio_path):\n",
    "    data, _ = librosa.load(audio_path) \n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data)\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "features_list = []\n",
    "\n",
    "\n",
    "for index, row in RAV_df.iterrows():\n",
    "    mean, std = compute_features(row['path'])\n",
    "    features_list.append({'Emotion': row['labels'], 'Mean': mean, 'std': std})\n",
    "\n",
    "features_df = pd.DataFrame(features_list)\n",
    "\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=features_df, x='Emotion', y='Mean')\n",
    "plt.title('Mean of Audio Signals by Emotion')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=features_df, x='Emotion', y='std')\n",
    "plt.title('Standard Deviation of Audio Signals by Emotion')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd08e25-b4ff-4604-a47d-72380d8a0502",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c93d8be-9b05-456a-b215-7761420025c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303119cd-38e2-4af1-a23e-278be6465cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ef309f-6a04-4288-b8ba-a4aa71796204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15420bba-3e15-4bc4-b86e-2aa8fa38902b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SentiAnalysis",
   "language": "python",
   "name": "sentianalysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
